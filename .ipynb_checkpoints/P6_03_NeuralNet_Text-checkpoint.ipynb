{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First preprocessing found here : https://towardsdatascience.com/deep-transfer-learning-for-natural-language-processing-text-classification-with-universal-1a2c69e5baa9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Importation\" data-toc-modified-id=\"Data-Importation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Importation</a></span></li><li><span><a href=\"#Neural-Network-for-text\" data-toc-modified-id=\"Neural-Network-for-text-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Neural Network for text</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data Preprocessing</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\__init__.py:29: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten, Embedding\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import layers, models, Model, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "import tensorflow\n",
    "import keras\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1337)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "target = pd.read_csv('data/target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[data['label'] == 'Train']['description']\n",
    "x_val = data[data['label'] == 'Validation']['description']\n",
    "x_test = data[data['label'] == 'Test']['description']\n",
    "\n",
    "target.categ = pd.Categorical(target.categ)\n",
    "target['categ_number'] = np.int32(target.categ.cat.codes)\n",
    "\n",
    "y_train = np.asarray(target[target['label'] == 'Train'][['categ_number']])\n",
    "y_val = np.asarray(target[target['label'] == 'Validation'][['categ_number']])\n",
    "y_test = np.asarray(target[target['label'] == 'Test'][['categ_number']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_val = tokenizer.texts_to_sequences(x_val)\n",
    "X_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 50)           232200    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               500100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 77        \n",
      "=================================================================\n",
      "Total params: 733,607\n",
      "Trainable params: 733,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, \n",
    "                    output_dim=50, \n",
    "                    input_length=maxlen))\n",
    "#model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLogs(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def set_params(self, params):\n",
    "        params['epochs'] = 0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print('Epoch %d/%d' % (epoch + 1, self.epochs), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 630 samples, validate on 210 samples\n",
      "Epoch 1/0\n",
      "630/630 [==============================] - 0s 757us/step - loss: 1.9182 - accuracy: 0.1635 - val_loss: 1.8787 - val_accuracy: 0.1857\n",
      "Epoch 2/0\n",
      "630/630 [==============================] - 0s 88us/step - loss: 1.8000 - accuracy: 0.2063 - val_loss: 1.7994 - val_accuracy: 0.2143\n",
      "Epoch 3/0\n",
      "630/630 [==============================] - 0s 110us/step - loss: 1.6662 - accuracy: 0.2873 - val_loss: 1.7114 - val_accuracy: 0.3381\n",
      "Epoch 4/0\n",
      "630/630 [==============================] - 0s 99us/step - loss: 1.4600 - accuracy: 0.4667 - val_loss: 1.5504 - val_accuracy: 0.3810\n",
      "Epoch 5/0\n",
      "630/630 [==============================] - 0s 85us/step - loss: 1.1798 - accuracy: 0.6016 - val_loss: 1.3906 - val_accuracy: 0.4905\n",
      "Epoch 6/0\n",
      "630/630 [==============================] - 0s 74us/step - loss: 0.8481 - accuracy: 0.6714 - val_loss: 1.1870 - val_accuracy: 0.5048\n",
      "Epoch 7/0\n",
      "630/630 [==============================] - 0s 85us/step - loss: 0.6003 - accuracy: 0.7206 - val_loss: 1.0766 - val_accuracy: 0.5619\n",
      "Epoch 8/0\n",
      "630/630 [==============================] - 0s 110us/step - loss: 0.4494 - accuracy: 0.8413 - val_loss: 1.0418 - val_accuracy: 0.6381\n",
      "Epoch 9/0\n",
      "630/630 [==============================] - 0s 99us/step - loss: 0.3497 - accuracy: 0.8587 - val_loss: 1.0087 - val_accuracy: 0.6238\n",
      "Epoch 10/0\n",
      "630/630 [==============================] - 0s 85us/step - loss: 0.2855 - accuracy: 0.8587 - val_loss: 0.9599 - val_accuracy: 0.6571\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[PrintLogs(epochs)],\n",
    "                    batch_size=32,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 25us/step\n",
      "Training Accuracy: 0.8841\n",
      "210/210 [==============================] - 0s 74us/step\n",
      "Testing Accuracy:  0.6952\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=1)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
